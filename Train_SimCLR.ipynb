{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train_SimCLR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvignav/SimCLR/blob/main/Train_SimCLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsi65mRTMl0G"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "YqzIOfEZMl0R"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 \n",
        "\n",
        "from evaluate_features import get_features, linear_classifier, tSNE_vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbpMmt6uMl0Z"
      },
      "source": [
        "# Load Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRGSbHANMl0a"
      },
      "source": [
        "import csv\n",
        "class_labels = [\"none\", \"mild\", \"moderate\", \"severe\", \"proliferative\"]\n",
        "\n",
        "csv_file = open('data/trainLabels.csv', mode='r')\n",
        "d = csv.DictReader(csv_file)\n",
        "\n",
        "fname = []\n",
        "label = []\n",
        "one_hot = []\n",
        "\n",
        "for row in d:\n",
        "    fname.append('data/train/' + row['image'] + '.jpeg')\n",
        "    l = int(row['level'])\n",
        "    label.append(class_labels[l])\n",
        "    arr = [0, 0, 0, 0, 0]\n",
        "    arr[l] = 1\n",
        "    one_hot.append(arr)\n",
        "\n",
        "df = pd.DataFrame({\"filename\": fname, \"class_label\": label, \"class_one_hot\": one_hot})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-YZpNjEMl0g",
        "outputId": "902ed152-b99e-414f-f83c-47a2aa8c10cd"
      },
      "source": [
        "num_classes = len(df['class_one_hot'][0])\n",
        "\n",
        "print(\"# of training instances:\", len(df.index), \"\\n\")\n",
        "for label in class_labels:\n",
        "    print(f\"# of '{label}' training instances: {(df.class_label == label).sum()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training instances: 35126 \n",
            "\n",
            "# of 'none' training instances: 25810\n",
            "# of 'mild' training instances: 2443\n",
            "# of 'moderate' training instances: 5292\n",
            "# of 'severe' training instances: 873\n",
            "# of 'proliferative' training instances: 708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2qU1NriMl0n",
        "outputId": "cf6afe2a-990a-4fe7-c1d1-d9b429896dbb"
      },
      "source": [
        "df_train, df_val_test = train_test_split(df, test_size=0.30, random_state=42, shuffle=True)\n",
        "df_val, df_test = train_test_split(df_val_test, test_size=0.50, random_state=42, shuffle=True)\n",
        "\n",
        "print(\"# of training instances:\", len(df_train.index), \"\\n\")\n",
        "for label in class_labels:\n",
        "    print(f\"# of '{label}' training instances: {(df_train.class_label == label).sum()}\")\n",
        "    \n",
        "print()\n",
        "print(\"# of validation instances:\", len(df_val.index), \"\\n\")\n",
        "for label in class_labels:\n",
        "    print(f\"# of '{label}' training instances: {(df_val.class_label == label).sum()}\")\n",
        "\n",
        "print()\n",
        "print(\"# of test instances:\", len(df_test.index), \"\\n\")\n",
        "for label in class_labels:\n",
        "    print(f\"# of '{label}' training instances: {(df_test.class_label == label).sum()}\")\n",
        "    \n",
        "dfs = {\n",
        "    \"train\": df_train,\n",
        "    \"val\": df_val,\n",
        "    \"test\": df_test\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training instances: 24588 \n",
            "\n",
            "# of 'none' training instances: 18045\n",
            "# of 'mild' training instances: 1725\n",
            "# of 'moderate' training instances: 3707\n",
            "# of 'severe' training instances: 621\n",
            "# of 'proliferative' training instances: 490\n",
            "\n",
            "# of validation instances: 5269 \n",
            "\n",
            "# of 'none' training instances: 3877\n",
            "# of 'mild' training instances: 358\n",
            "# of 'moderate' training instances: 781\n",
            "# of 'severe' training instances: 134\n",
            "# of 'proliferative' training instances: 119\n",
            "\n",
            "# of test instances: 5269 \n",
            "\n",
            "# of 'none' training instances: 3888\n",
            "# of 'mild' training instances: 360\n",
            "# of 'moderate' training instances: 804\n",
            "# of 'severe' training instances: 118\n",
            "# of 'proliferative' training instances: 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "N9GgCItGMl0u"
      },
      "source": [
        "# Img size\n",
        "size = 128\n",
        "height_img = size\n",
        "width_img = size\n",
        "\n",
        "input_shape = (height_img, width_img, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYrLvS3iMl0y"
      },
      "source": [
        "# Load pretrained VGG16 & Feature evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z587NS5Ml00",
        "outputId": "29908c5e-b50b-4eb1-e33d-cbb4f0c787f0"
      },
      "source": [
        "params_vgg16 = {'weights': \"imagenet\", \n",
        "                'include_top': False, \n",
        "                'input_shape': input_shape, \n",
        "                'pooling': None}\n",
        "\n",
        "# Design model\n",
        "base_model = VGG16(**params_vgg16)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XcdE2JU5Ml04"
      },
      "source": [
        "feat_dim = 2 * 2 * 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75j95YbIMl09"
      },
      "source": [
        "# Build SimCLR-Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNq93i59Ml0-",
        "outputId": "91b9aa6c-9257-4b0c-82d6-f18dafc50c53"
      },
      "source": [
        "from DataGeneratorSimCLR import DataGeneratorSimCLR as DataGenerator\n",
        "from SimCLR import SimCLR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0_nz95NMl1D"
      },
      "source": [
        "### Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EqkkdfRPMl1E"
      },
      "source": [
        "batch_size = 16\n",
        "# Projection_head\n",
        "num_layers_ph = 2\n",
        "feat_dims_ph = [2048, 128]\n",
        "num_of_unfrozen_layers = 4\n",
        "save_path = 'models/dr'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "X1dGZztKMl1K"
      },
      "source": [
        "SimCLR = SimCLR(\n",
        "        base_model = base_model,\n",
        "        input_shape = input_shape,\n",
        "        batch_size = batch_size,\n",
        "        feat_dim = feat_dim,\n",
        "        feat_dims_ph = feat_dims_ph,\n",
        "        num_of_unfrozen_layers = num_of_unfrozen_layers,\n",
        "        save_path = save_path\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bvdVxJTiMl1W"
      },
      "source": [
        "params_generator = {'batch_size': batch_size,\n",
        "                    'shuffle' : True,\n",
        "                    'width':width_img,\n",
        "                    'height': height_img,\n",
        "                    'VGG': True\n",
        "                   }\n",
        "\n",
        "# Generators\n",
        "data_train = DataGenerator(df_train.reset_index(drop=True), **params_generator)\n",
        "data_val = DataGenerator(df_val.reset_index(drop=True), subset = \"val\", **params_generator) #val keeps the unity values on the same random places ~42\n",
        "data_test = DataGenerator(df_test.reset_index(drop=True), subset = \"test\", **params_generator) #test keeps the unity values on the diagonal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pssY8CS6Ml1g"
      },
      "source": [
        "## Training SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "JLMsqpJcMl1h",
        "outputId": "4df6a650-cdfd-4f02-bd88-978690701b1c"
      },
      "source": [
        "SimCLR.unfreeze_and_train(data_train, \n",
        "                          data_val, \n",
        "                          num_of_unfrozen_layers = 4, \n",
        "                          r = 4, \n",
        "                          lr = 1e-6,\n",
        "                          epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable parameters: 24.12 M.\n",
            "non-trainable parameters: 7.64 M.\n",
            "Train for 1537 steps, validate for 330 steps\n",
            "Epoch 1/5\n",
            "1536/1537 [============================>.] - ETA: 3s - loss: 993.3493\n",
            "Epoch 00001: val_loss improved from inf to 934.88759, saving model to /scratch/users/rvignav/models/dr/SimCLR/SimCLR_07_14_01h_21.h5\n",
            "1537/1537 [==============================] - 6969s 5s/step - loss: 993.3114 - val_loss: 934.8876\n",
            "Epoch 2/5\n",
            "1536/1537 [============================>.] - ETA: 3s - loss: 878.7364\n",
            "Epoch 00002: val_loss improved from 934.88759 to 823.52380, saving model to /scratch/users/rvignav/models/dr/SimCLR/SimCLR_07_14_01h_21.h5\n",
            "1537/1537 [==============================] - 6881s 4s/step - loss: 878.7006 - val_loss: 823.5238\n",
            "Epoch 3/5\n",
            "1536/1537 [============================>.] - ETA: 3s - loss: 770.8118\n",
            "Epoch 00003: val_loss improved from 823.52380 to 719.20680, saving model to /scratch/users/rvignav/models/dr/SimCLR/SimCLR_07_14_01h_21.h5\n",
            "1537/1537 [==============================] - 6992s 5s/step - loss: 770.7783 - val_loss: 719.2068\n",
            "Epoch 4/5\n",
            "1536/1537 [============================>.] - ETA: 3s - loss: 670.2253\n",
            "Epoch 00004: val_loss improved from 719.20680 to 622.37751, saving model to /scratch/users/rvignav/models/dr/SimCLR/SimCLR_07_14_01h_21.h5\n",
            "1537/1537 [==============================] - 7104s 5s/step - loss: 670.1942 - val_loss: 622.3775\n",
            "Epoch 5/5\n",
            "1536/1537 [============================>.] - ETA: 3s - loss: 577.1874\n",
            "Epoch 00005: val_loss improved from 622.37751 to 533.14481, saving model to /scratch/users/rvignav/models/dr/SimCLR/SimCLR_07_14_01h_21.h5\n",
            "1537/1537 [==============================] - 7254s 5s/step - loss: 577.1588 - val_loss: 533.1448\n",
            "trainable parameters: 24.12 M.\n",
            "non-trainable parameters: 7.64 M.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}